{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f4f572",
   "metadata": {},
   "source": [
    "#### Tokenization using Hugging Face's Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ed5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AutoTokenizer class from Hugging Face's transformers library\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the pretrained GPT-2 tokenizer\n",
    "# This will automatically download the tokenizer configuration for GPT-2 if not already available\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt-2\")\n",
    "\n",
    "# Tokenize the input text\n",
    "# This process splits the text into tokens that GPT-2 can understand (subwords or words)\n",
    "tokens = tokenizer.tokenize(\"A young girl named Alice sits bored by a riverbank...\")\n",
    "\n",
    "# Print the list of tokens generated by the tokenizer\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a76a0",
   "metadata": {},
   "source": [
    "#### Embedding and Processing with a Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25152a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AutoModel class to load a pretrained model from Hugging Face\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Load the pretrained GPT-2 model\n",
    "# This model will generate embeddings for the input text\n",
    "model = AutoModel.from_pretrained(\"gpt-2\")\n",
    "\n",
    "# Tokenize the input text and convert it to tensor format for model input\n",
    "# The 'return_tensors=\"pt\"' argument specifies that the output should be in PyTorch tensor format\n",
    "inputs = tokenizer(\"A young girl named Alice sits bored by a riverbank...\", return_tensors=\"pt\")\n",
    "\n",
    "# Pass the tokenized inputs through the model\n",
    "# The '**inputs' syntax unpacks the dictionary, allowing each tensor (e.g., input IDs) to be passed as a named argument\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract the last hidden states from the model outputs\n",
    "# 'last_hidden_state' contains embeddings for each token in the input text\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Print the shape of the last hidden states tensor to understand the output structure\n",
    "print(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7e440",
   "metadata": {},
   "source": [
    "#### Visualization of Embeddings (Simplified Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84297a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the embeddings using a heatmap\n",
    "# 'detach().numpy()' detaches the tensor from the computation graph and converts it to a NumPy array\n",
    "# '[0]' selects the embeddings for the first sequence (useful if batching multiple sequences)\n",
    "plt.imshow(last_hidden_states.detach().numpy()[0], cmap='viridis')\n",
    "\n",
    "# Add a color bar to indicate the scale of values in the heatmap\n",
    "plt.colorbar()\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
